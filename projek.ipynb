import torch, torch.nn as nn, torch.optim as optim
import numpy as np, matplotlib.pyplot as plt
from torch.utils.data import DataLoader, random_split, Dataset
from torchvision import datasets, models, transforms
from torch.amp import GradScaler, autocast
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc
from sklearn.preprocessing import label_binarize
from tqdm import tqdm
from itertools import cycle

# --- KONFIGURASI ---
CONF = {'data': r'D:\Kuliah\joki\joki radit\irgi\dataset\pest\train', 'dev': torch.device("cuda" if torch.cuda.is_available() else "cpu")}
print(f"Device: {CONF['dev']}")

# --- UTILS: DATASET WRAPPER ---
class Wrapper(Dataset):
    def __init__(self, sub, tfm): self.sub, self.tfm = sub, tfm
    def __getitem__(self, i): x, y = self.sub[i]; return (self.tfm(x) if self.tfm else x), y
    def __len__(self): return len(self.sub)

# --- UTILS: CORE ENGINE (Train & Eval) ---
def train_engine(model, train_loader, epochs, lr, name, use_amp=False, scheduler=None):
    print(f"\n=== Training {name} ===")
    opt = optim.Adam(model.parameters(), lr=lr)
    crit = nn.CrossEntropyLoss()
    scaler = GradScaler('cuda') if use_amp else None
    
    for ep in range(epochs):
        model.train()
        loop = tqdm(train_loader, desc=f"Ep {ep+1}/{epochs}")
        for x, y in loop:
            x, y = x.to(CONF['dev']), y.to(CONF['dev'])
            opt.zero_grad()
            
            with autocast('cuda', enabled=use_amp):
                loss = crit(model(x), y)
            
            if scaler: scaler.scale(loss).backward(); scaler.step(opt); scaler.update()
            else: loss.backward(); opt.step()
            
            if scheduler: scheduler.step()
            loop.set_postfix(loss=loss.item())
    
    torch.save(model.state_dict(), f'{name}.pth')
    return model

def evaluate(model, loader, classes, name):
    model.eval()
    y_true, y_pred, y_prob = [], [], []
    with torch.no_grad():
        for x, y in tqdm(loader, desc="Eval"):
            out = model(x.to(CONF['dev']))
            y_true.extend(y.cpu().numpy())
            y_pred.extend(out.argmax(1).cpu().numpy())
            y_prob.extend(out.softmax(1).cpu().numpy())

    print(f"\nReport {name}:\n", classification_report(y_true, y_pred, target_names=classes))
    
    # Plot CM
    disp = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred), display_labels=classes)
    disp.plot(cmap='Blues', xticks_rotation=45); plt.title(f'CM - {name}'); plt.show()

    # Plot ROC
    plt.figure(figsize=(8, 6))
    y_bin, y_prob = label_binarize(y_true, classes=range(len(classes))), np.array(y_prob)
    for i, c in enumerate(classes):
        fpr, tpr, _ = roc_curve(y_bin[:, i], y_prob[:, i])
        plt.plot(fpr, tpr, label=f'{c} (AUC={auc(fpr, tpr):.2f})')
    plt.plot([0,1],[0,1],'k--'); plt.legend(); plt.title(f'ROC - {name}'); plt.show()

# --- MAIN ---
if __name__ == '__main__':
    # 1. Load Data
    full_ds = datasets.ImageFolder(CONF['data'])
    splits = [int(len(full_ds)*r) for r in [0.7, 0.15]]
    splits.append(len(full_ds) - sum(splits))
    sets = random_split(full_ds, splits, generator=torch.Generator().manual_seed(42))
    
    # 2. Transforms
    base = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    tfms = {
        's1': transforms.Compose([transforms.Resize((160,160)), transforms.RandomHorizontalFlip(), transforms.ToTensor(), base]),
        's2': transforms.Compose([transforms.Resize((224,224)), transforms.RandomRotation(15), transforms.ToTensor(), base]),
        'val': lambda sz: transforms.Compose([transforms.Resize((sz,sz)), transforms.ToTensor(), base])
    }

    # --- SKEMA 1: MobileNetV3 (Frozen) ---
    dl_train = DataLoader(Wrapper(sets[0], tfms['s1']), batch_size=64, shuffle=True, num_workers=0)
    dl_test  = DataLoader(Wrapper(sets[2], tfms['val'](160)), batch_size=64, num_workers=0)
    
    m1 = models.mobilenet_v3_small(weights='DEFAULT')
    for p in m1.features.parameters(): p.requires_grad = False
    m1.classifier[3] = nn.Linear(m1.classifier[3].in_features, len(full_ds.classes))
    
    m1 = train_engine(m1.to(CONF['dev']), dl_train, epochs=5, lr=1e-3, name="MobileNet_Minimalist")
    evaluate(m1, dl_test, full_ds.classes, "MobileNet")

    # --- SKEMA 2: ShuffleNet (AMP + Scheduler) ---
    dl_train = DataLoader(Wrapper(sets[0], tfms['s2']), batch_size=32, shuffle=True, num_workers=0, pin_memory=True)
    dl_test  = DataLoader(Wrapper(sets[2], tfms['val'](224)), batch_size=32, num_workers=0, pin_memory=True)

    m2 = models.shufflenet_v2_x0_5(weights='DEFAULT')
    m2.fc = nn.Linear(m2.fc.in_features, len(full_ds.classes))
    
    # Setup Scheduler outside
    dummy_opt = optim.Adam(m2.parameters(), lr=1e-3) 
    sched = optim.lr_scheduler.OneCycleLR(dummy_opt, max_lr=0.01, steps_per_epoch=len(dl_train), epochs=8)
    
    m2 = train_engine(m2.to(CONF['dev']), dl_train, epochs=8, lr=1e-3, name="ShuffleNet_Speed", use_amp=True, scheduler=sched)
    evaluate(m2, dl_test, full_ds.classes, "ShuffleNet")
    
    print("\nSELESAI.")
